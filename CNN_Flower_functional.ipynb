{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "original_dataset_dir = 'D://flowers'\n",
    "original_dataset_dir = os.path.join(original_dataset_dir,'flowers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/keras-functional-api-deep-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D://flowers\\flowers\n"
     ]
    }
   ],
   "source": [
    "print(original_dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "flower_names = os.listdir(original_dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_train = os.path.join(original_dataset_dir,'train')\n",
    "#os.mkdir(flower_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_test = os.path.join(original_dataset_dir,'test')\n",
    "#os.mkdir(flower_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_flower_dir():\n",
    "    for flower_name in flower_names:\n",
    "        flower_path = os.path.join(original_dataset_dir,flower_name)\n",
    "        flowerslist = os.listdir(flower_path)\n",
    "        flower_train = os.path.join(original_dataset_dir,'train')\n",
    "        flower_train = os.path.join(flower_train,flower_name)\n",
    "        flower_test = os.path.join(original_dataset_dir,'test')\n",
    "        flower_test = os.path.join(flower_test,flower_name)\n",
    "        os.mkdir(flower_train)\n",
    "        os.mkdir(flower_test)\n",
    "        print(len(flowerslist))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_flower_in_set():\n",
    "    train_count = 0\n",
    "    test_count =0\n",
    "    dsttest = os.path.join(original_dataset_dir,'test')\n",
    "    dsttrain = os.path.join(original_dataset_dir,'train')\n",
    "    flower_names = os.listdir(dsttest)\n",
    "    for flower_name in flower_names:\n",
    "        test_dst = os.path.join(dsttest,flower_name)\n",
    "        test_count = test_count + len(os.listdir(test_dst))\n",
    "        train_dst = os.path.join(dsttrain,flower_name)\n",
    "        train_count = train_count + len(os.listdir(train_dst))\n",
    "        print(flower_name)\n",
    "        print(test_dst)\n",
    "        print(len(os.listdir(test_dst)))\n",
    "    return train_count,test_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "daisy\n",
      "D://flowers\\flowers\\test\\daisy\n",
      "101\n",
      "dandelion\n",
      "D://flowers\\flowers\\test\\dandelion\n",
      "101\n",
      "rose\n",
      "D://flowers\\flowers\\test\\rose\n",
      "101\n",
      "sunflower\n",
      "D://flowers\\flowers\\test\\sunflower\n",
      "101\n",
      "tulip\n",
      "D://flowers\\flowers\\test\\tulip\n",
      "101\n"
     ]
    }
   ],
   "source": [
    "train_c,test_c=total_flower_in_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3821, 505)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_c,test_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets talk 100 each in test set and rest in training set\n",
    "#create_flower_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_flower_per_cat():\n",
    "    for flower_name in flower_names:\n",
    "        flower_path = os.path.join(original_dataset_dir,flower_name)\n",
    "        flowerslist = os.listdir(flower_path)\n",
    "        for i,flower in enumerate(flowerslist):\n",
    "            print(flower)\n",
    "            if(i<=100):\n",
    "                #copy in test\n",
    "                src = os.path.join(original_dataset_dir,flower_name)\n",
    "                src = os.path.join(src,flower)\n",
    "                test_dst = os.path.join(original_dataset_dir,'test')\n",
    "                test_dst = os.path.join(test_dst,flower_name)\n",
    "                test_dst = os.path.join(test_dst,flower)\n",
    "                #print(test_dst)\n",
    "                shutil.copyfile(src, test_dst)\n",
    "            else:\n",
    "                #copy in train\n",
    "                src = os.path.join(original_dataset_dir,flower_name)\n",
    "                src = os.path.join(src,flower)\n",
    "                train_dst = os.path.join(original_dataset_dir,'train')\n",
    "                train_dst = os.path.join(train_dst,flower_name)\n",
    "                train_dst = os.path.join(train_dst,flower)\n",
    "                shutil.copyfile(src, train_dst)\n",
    "                \n",
    "                \n",
    "             \n",
    "            \n",
    "        \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy_flower_per_cat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3818 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "        flower_train,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=500,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [0., 0.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "sample_change = np.zeros(shape=(2,2))\n",
    "sample_change\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_change[1]=[2,4]\n",
    "sample_change[0]=[1,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 5.],\n",
       "       [2., 4.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 150, 150, 3)\n",
      "(500, 5)\n",
      "(500, 150, 150, 3)\n",
      "(500, 5)\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for data,label in train_generator:\n",
    "    if i<2:\n",
    "         print(data.shape)\n",
    "         print(label.shape)\n",
    "    else:\n",
    "        break\n",
    "    i = i+1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3821, 505)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_c,test_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "train_data_feature = np.zeros(shape=(3821, 150, 150, 3))\n",
    "train_data_label = np.zeros(shape=(3821,5))\n",
    "test_data_feature = np.zeros(shape=(505, 150, 150, 3))\n",
    "test_data_label = np.zeros(shape=(505, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "batch_size=500\n",
    "for input_batch,label_batch in train_generator:\n",
    "    if ((i*batch_size) < 3821):\n",
    "        train_data_feature[i*batch_size:(i+1)*batch_size] = input_batch\n",
    "        train_data_label[i*batch_size:(i+1)*batch_size] = label_batch\n",
    "    if(len(input_batch)<batch_size):\n",
    "        size=len(input_batch)\n",
    "        train_data_feature[i*batch_size:size] = input_batch\n",
    "        train_data_label[i*batch_size:size] = label_batch\n",
    "    else:\n",
    "        break\n",
    "    i=i+1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[0.40827894, 0.32857603, 0.00160943],\n",
       "         [0.29716432, 0.21372734, 0.01414239],\n",
       "         [0.41895887, 0.31208545, 0.00793715],\n",
       "         ...,\n",
       "         [0.59679985, 0.63192016, 0.02739165],\n",
       "         [0.5920794 , 0.62664396, 0.00895715],\n",
       "         [0.59074223, 0.62270266, 0.01100016]],\n",
       " \n",
       "        [[0.2555562 , 0.20310466, 0.01341108],\n",
       "         [0.13182573, 0.10339394, 0.0312696 ],\n",
       "         [0.27083352, 0.21186383, 0.0052064 ],\n",
       "         ...,\n",
       "         [0.63630277, 0.67188847, 0.03541632],\n",
       "         [0.61951745, 0.65149957, 0.04119094],\n",
       "         [0.60355365, 0.63651693, 0.02290446]],\n",
       " \n",
       "        [[0.11538032, 0.09405175, 0.02143819],\n",
       "         [0.06052946, 0.06135727, 0.0474686 ],\n",
       "         [0.1863907 , 0.15679474, 0.00179192],\n",
       "         ...,\n",
       "         [0.65511942, 0.68342489, 0.04205416],\n",
       "         [0.64715606, 0.68007082, 0.06799167],\n",
       "         [0.62780273, 0.65781975, 0.03910025]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.89406461, 0.88713264, 0.89308643],\n",
       "         [0.57785422, 0.46477965, 0.28166187],\n",
       "         [0.42035261, 0.40164009, 0.11861884],\n",
       "         ...,\n",
       "         [0.51381999, 0.69847423, 0.98082715],\n",
       "         [0.51045823, 0.69477195, 0.97712493],\n",
       "         [0.50437313, 0.68868685, 0.97103983]],\n",
       " \n",
       "        [[0.93652284, 0.85657322, 0.75994104],\n",
       "         [0.53554559, 0.42225149, 0.11523554],\n",
       "         [0.42837498, 0.40393999, 0.1225964 ],\n",
       "         ...,\n",
       "         [0.51110482, 0.69585353, 0.97820652],\n",
       "         [0.50783938, 0.69215316, 0.97450608],\n",
       "         [0.50312501, 0.68743879, 0.96979171]],\n",
       " \n",
       "        [[0.74980301, 0.72841066, 0.79606968],\n",
       "         [0.4746224 , 0.39768812, 0.14507633],\n",
       "         [0.41193432, 0.38930404, 0.0582765 ],\n",
       "         ...,\n",
       "         [0.50787294, 0.69455266, 0.97690558],\n",
       "         [0.5097906 , 0.68904245, 0.97320336],\n",
       "         [0.50717086, 0.68497998, 0.96613073]]]), array([0., 0., 0., 1., 0.]))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_feature[4],train_data_label[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 505 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        flower_test,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=50,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "batch_size=50\n",
    "for input_batch,label_batch in validation_generator:\n",
    "    if ((i*batch_size) < 3821):\n",
    "        test_data_feature[i*batch_size:(i+1)*batch_size] = input_batch\n",
    "        test_data_label[i*batch_size:(i+1)*batch_size] = label_batch\n",
    "    if(len(input_batch)<batch_size):\n",
    "        size=len(input_batch)\n",
    "        test_data_feature[i*batch_size:size] = input_batch\n",
    "        test_data_label[i*batch_size:size] = label_batch\n",
    "    else:\n",
    "        break\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[0.7843138 , 0.78039223, 0.84313732],\n",
       "         [0.7843138 , 0.78039223, 0.84313732],\n",
       "         [0.78823537, 0.7843138 , 0.84705889],\n",
       "         ...,\n",
       "         [0.72549021, 0.72941178, 0.80784321],\n",
       "         [0.72156864, 0.72549021, 0.80392164],\n",
       "         [0.72156864, 0.72549021, 0.80392164]],\n",
       " \n",
       "        [[0.78039223, 0.77647066, 0.83921576],\n",
       "         [0.78039223, 0.77647066, 0.83921576],\n",
       "         [0.7843138 , 0.78039223, 0.84313732],\n",
       "         ...,\n",
       "         [0.72549021, 0.72941178, 0.80784321],\n",
       "         [0.72156864, 0.72549021, 0.80392164],\n",
       "         [0.72156864, 0.72549021, 0.80392164]],\n",
       " \n",
       "        [[0.77254909, 0.78039223, 0.83921576],\n",
       "         [0.77254909, 0.78039223, 0.83921576],\n",
       "         [0.77647066, 0.7843138 , 0.84313732],\n",
       "         ...,\n",
       "         [0.72549021, 0.72941178, 0.80784321],\n",
       "         [0.72549021, 0.72941178, 0.80784321],\n",
       "         [0.72156864, 0.72549021, 0.80392164]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.41176474, 0.48627454, 0.40784317],\n",
       "         [0.07058824, 0.12156864, 0.05490196],\n",
       "         [0.37647063, 0.40000004, 0.36078432],\n",
       "         ...,\n",
       "         [0.39607847, 0.33725491, 0.26274511],\n",
       "         [0.25882354, 0.18823531, 0.14117648],\n",
       "         [0.17647059, 0.23137257, 0.17254902]],\n",
       " \n",
       "        [[0.25882354, 0.27058825, 0.0627451 ],\n",
       "         [0.1254902 , 0.1137255 , 0.07843138],\n",
       "         [0.5411765 , 0.6156863 , 0.52941179],\n",
       "         ...,\n",
       "         [0.34901962, 0.34509805, 0.26666668],\n",
       "         [0.23529413, 0.21176472, 0.14901961],\n",
       "         [0.07450981, 0.09803922, 0.05882353]],\n",
       " \n",
       "        [[0.81176478, 0.61960787, 0.1137255 ],\n",
       "         [0.49411768, 0.5529412 , 0.43921572],\n",
       "         [0.6156863 , 0.63921571, 0.52941179],\n",
       "         ...,\n",
       "         [0.19215688, 0.1137255 , 0.08627451],\n",
       "         [0.22352943, 0.15686275, 0.11764707],\n",
       "         [0.16078432, 0.21568629, 0.16470589]]]), array([0., 0., 0., 1., 0.]))"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_feature[4],test_data_label[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python3\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense,Dropout,Conv2D,MaxPool2D,Flatten,Input\n",
    "from keras.models import Model\n",
    "\n",
    "vision= Input(shape=(150,150,3))\n",
    "conv2d_1=Conv2D(32,(3,3),activation='relu')(vision)\n",
    "maxpool1=MaxPool2D(2,2)(conv2d_1)\n",
    "conv2d_2=Conv2D(32,(3,3),activation='relu')(maxpool1)\n",
    "maxpool2=MaxPool2D(2,2)(conv2d_2)\n",
    "conv2d_3=Conv2D(32,(3,3),activation='relu')(maxpool2)\n",
    "maxpool3=MaxPool2D(2,2)(conv2d_3)\n",
    "flat=Flatten()(maxpool3)\n",
    "dense=Dense(512,activation='relu')(flat)\n",
    "output= Dense(5,activation='softmax')(dense)\n",
    "model_func = Model(input=vision,output=output)\n",
    "model_func.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['acc'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 72, 72, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 36, 36, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 34, 34, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 17, 17, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 9248)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               4735488   \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 4,757,445\n",
      "Trainable params: 4,757,445\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_func.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0814 10:43:55.386344  5480 deprecation.py:323] From c:\\python3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0814 10:43:55.547546  5480 deprecation_wrapper.py:119] From c:\\python3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3821 samples, validate on 505 samples\n",
      "Epoch 1/12\n",
      "3821/3821 [==============================] - 64s 17ms/step - loss: 0.2130 - acc: 0.1955 - val_loss: 0.1339 - val_acc: 0.0455\n",
      "Epoch 2/12\n",
      "3821/3821 [==============================] - 65s 17ms/step - loss: 0.1795 - acc: 0.2319 - val_loss: 0.1404 - val_acc: 0.9584\n",
      "Epoch 3/12\n",
      "3821/3821 [==============================] - 72s 19ms/step - loss: 0.1398 - acc: 0.3156 - val_loss: 0.1153 - val_acc: 0.0515\n",
      "Epoch 4/12\n",
      "3821/3821 [==============================] - 68s 18ms/step - loss: 0.1119 - acc: 0.1175 - val_loss: 0.1115 - val_acc: 0.0535\n",
      "Epoch 5/12\n",
      "3821/3821 [==============================] - 75s 20ms/step - loss: 0.0690 - acc: 0.1065 - val_loss: 0.2037 - val_acc: 0.0535\n",
      "Epoch 6/12\n",
      "3821/3821 [==============================] - 68s 18ms/step - loss: 0.0376 - acc: 0.1183 - val_loss: 0.2326 - val_acc: 0.0495\n",
      "Epoch 7/12\n",
      "3821/3821 [==============================] - 73s 19ms/step - loss: 0.0279 - acc: 0.1222 - val_loss: 0.2989 - val_acc: 0.0554\n",
      "Epoch 8/12\n",
      "3821/3821 [==============================] - 67s 18ms/step - loss: 0.0168 - acc: 0.1361 - val_loss: 0.2969 - val_acc: 0.0475\n",
      "Epoch 9/12\n",
      "3821/3821 [==============================] - 66s 17ms/step - loss: 0.0172 - acc: 0.2625 - val_loss: 0.3315 - val_acc: 0.0475\n",
      "Epoch 10/12\n",
      "3821/3821 [==============================] - 73s 19ms/step - loss: 0.0109 - acc: 0.1403 - val_loss: 0.6081 - val_acc: 0.0337\n",
      "Epoch 11/12\n",
      "3821/3821 [==============================] - 71s 19ms/step - loss: 0.0142 - acc: 0.1282 - val_loss: 0.3780 - val_acc: 0.0495\n",
      "Epoch 12/12\n",
      "3821/3821 [==============================] - 69s 18ms/step - loss: 0.0297 - acc: 0.1398 - val_loss: 0.5731 - val_acc: 0.0436\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21573208>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_func.fit(train_data_feature,train_data_label,batch_size=50,epochs=12,validation_data=(test_data_feature,test_data_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505/505 [==============================] - 2s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "score = model_func.evaluate(test_data_feature,test_data_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.5730922283512531 accuracy :  0.04356435643564356\n"
     ]
    }
   ],
   "source": [
    "print('loss:' , score[0], 'accuracy : ',score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4% accuracy is horrible lets try new more complicated model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0814 11:03:24.091115  5480 deprecation.py:506] From c:\\python3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 150, 150, 32)      896       \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 150, 150, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 75, 75, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 75, 75, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 75, 75, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 75, 75, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 37, 37, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 37, 37, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 43808)             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 512)               22430208  \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 22,461,413\n",
      "Trainable params: 22,461,413\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python3\\lib\\site-packages\\ipykernel_launcher.py:16: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "visible= Input(shape=(150,150,3))\n",
    "conv2d_1 = Conv2D(32,(3,3),activation='relu',padding='same')(visible)\n",
    "conv2d_2 = Conv2D(32,(3,3),activation='relu',padding='same')(conv2d_1)\n",
    "pool1= MaxPool2D(pool_size=(2,2))(conv2d_2)\n",
    "dropout1=Dropout(0.5)(pool1)\n",
    "\n",
    "conv2d_3 = Conv2D(32,(3,3),activation='relu',padding='same')(dropout1)\n",
    "conv2d_4 = Conv2D(32,(3,3),activation='relu',padding='same')(conv2d_3)\n",
    "pool2= MaxPool2D(pool_size=(2,2))(conv2d_4)\n",
    "dropout2=Dropout(0.5)(pool2)\n",
    "\n",
    "flat=Flatten()(dropout2)\n",
    "dense= Dense(512,activation='relu')(flat)\n",
    "dropout3=Dropout(0.5)(dense)\n",
    "output = Dense(5,activation='softmax')(dropout3)\n",
    "model = Model(input=visible,output=output)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3821 samples, validate on 505 samples\n",
      "Epoch 1/12\n",
      "3821/3821 [==============================] - 206s 54ms/step - loss: 1.7433 - acc: 0.0348 - val_loss: 1.2733 - val_acc: 0.0198\n",
      "Epoch 2/12\n",
      "3821/3821 [==============================] - 222s 58ms/step - loss: 1.7464 - acc: 0.0225 - val_loss: 1.2741 - val_acc: 0.0198\n",
      "Epoch 3/12\n",
      "3821/3821 [==============================] - 214s 56ms/step - loss: 1.7464 - acc: 0.0225 - val_loss: 1.2741 - val_acc: 0.0198\n",
      "Epoch 4/12\n",
      "3821/3821 [==============================] - 211s 55ms/step - loss: 1.7464 - acc: 0.0225 - val_loss: 1.2741 - val_acc: 0.0198\n",
      "Epoch 5/12\n",
      "3821/3821 [==============================] - 213s 56ms/step - loss: 1.2999 - acc: 0.1717 - val_loss: 0.1583 - val_acc: 0.9307\n",
      "Epoch 6/12\n",
      "3821/3821 [==============================] - 215s 56ms/step - loss: 0.2058 - acc: 0.2978 - val_loss: 0.1418 - val_acc: 0.0297\n",
      "Epoch 7/12\n",
      "3821/3821 [==============================] - 205s 54ms/step - loss: 0.1907 - acc: 0.1662 - val_loss: 0.1379 - val_acc: 0.0376\n",
      "Epoch 8/12\n",
      "3821/3821 [==============================] - 213s 56ms/step - loss: 0.1780 - acc: 0.6171 - val_loss: 0.1185 - val_acc: 0.9446\n",
      "Epoch 9/12\n",
      "3821/3821 [==============================] - 228s 60ms/step - loss: 0.1756 - acc: 0.6770 - val_loss: 0.1184 - val_acc: 0.0396\n",
      "Epoch 10/12\n",
      "3821/3821 [==============================] - 219s 57ms/step - loss: 0.1578 - acc: 0.5198 - val_loss: 0.1281 - val_acc: 0.9604\n",
      "Epoch 11/12\n",
      "3821/3821 [==============================] - 208s 54ms/step - loss: 0.1436 - acc: 0.3716 - val_loss: 0.1223 - val_acc: 0.0515\n",
      "Epoch 12/12\n",
      "3821/3821 [==============================] - 217s 57ms/step - loss: 0.1199 - acc: 0.1348 - val_loss: 0.1230 - val_acc: 0.0574\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21b2a888>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['acc'])\n",
    "model.fit(train_data_feature,train_data_label,batch_size=50,epochs=12,validation_data=(test_data_feature,test_data_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505/505 [==============================] - 2s 5ms/step\n",
      "loss: 0.5730922283512531 accuracy :  0.04356435643564356\n"
     ]
    }
   ],
   "source": [
    "score = model_func.evaluate(test_data_feature,test_data_label)\n",
    "print('loss:' , score[0], 'accuracy : ',score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense,Dropout,Conv2D,MaxPool2D,Flatten,Input\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_14 (Conv2D)           (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 72, 72, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 34, 34, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 17, 17, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 18496)             0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 512)               9470464   \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 9,529,349\n",
      "Trainable params: 9,529,349\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32,(3,3),activation='relu',input_shape=(150,150,3)))\n",
    "model.add(MaxPool2D(2,2))\n",
    "model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(MaxPool2D(2,2))\n",
    "model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(MaxPool2D(2,2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(Dense(5,activation='softmax'))\n",
    "model.summary()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "10/10 [==============================] - 151s 15s/step - loss: 1.0887 - acc: 0.5653 - val_loss: 1.0838 - val_acc: 0.5853\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 136s 14s/step - loss: 1.0784 - acc: 0.5791 - val_loss: 1.1039 - val_acc: 0.5789\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 140s 14s/step - loss: 1.0336 - acc: 0.6006 - val_loss: 1.0476 - val_acc: 0.6129\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 132s 13s/step - loss: 0.9766 - acc: 0.6100 - val_loss: 1.2758 - val_acc: 0.5389\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - 141s 14s/step - loss: 0.9399 - acc: 0.6301 - val_loss: 1.1195 - val_acc: 0.5763\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - 157s 16s/step - loss: 0.9569 - acc: 0.6291 - val_loss: 1.0850 - val_acc: 0.6101\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - 143s 14s/step - loss: 0.9821 - acc: 0.6260 - val_loss: 1.1865 - val_acc: 0.5332\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - 132s 13s/step - loss: 0.8744 - acc: 0.6639 - val_loss: 0.9145 - val_acc: 0.6527\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - 145s 15s/step - loss: 0.8236 - acc: 0.6791 - val_loss: 1.0542 - val_acc: 0.5793\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - 143s 14s/step - loss: 0.8384 - acc: 0.6723 - val_loss: 1.0324 - val_acc: 0.6289\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - 142s 14s/step - loss: 0.7732 - acc: 0.7020 - val_loss: 1.0860 - val_acc: 0.6022\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - 142s 14s/step - loss: 0.8077 - acc: 0.6881 - val_loss: 0.9220 - val_acc: 0.6724\n",
      "Epoch 13/20\n",
      "10/10 [==============================] - 147s 15s/step - loss: 0.7503 - acc: 0.7185 - val_loss: 0.9588 - val_acc: 0.6444\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - 141s 14s/step - loss: 0.6919 - acc: 0.7302 - val_loss: 1.0113 - val_acc: 0.6293\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - 135s 13s/step - loss: 0.7251 - acc: 0.7192 - val_loss: 0.8984 - val_acc: 0.6747\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - 132s 13s/step - loss: 0.6598 - acc: 0.7430 - val_loss: 1.0390 - val_acc: 0.6638\n",
      "Epoch 17/20\n",
      "10/10 [==============================] - 135s 14s/step - loss: 0.6875 - acc: 0.7392 - val_loss: 0.9756 - val_acc: 0.6611\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - 137s 14s/step - loss: 0.6742 - acc: 0.7425 - val_loss: 0.9539 - val_acc: 0.6772\n",
      "Epoch 19/20\n",
      "10/10 [==============================] - 142s 14s/step - loss: 0.5495 - acc: 0.7908 - val_loss: 1.1823 - val_acc: 0.5767\n",
      "Epoch 20/20\n",
      "10/10 [==============================] - 134s 13s/step - loss: 0.6359 - acc: 0.7560 - val_loss: 0.9169 - val_acc: 0.6690\n"
     ]
    }
   ],
   "source": [
    "history=model.fit_generator(train_generator,steps_per_epoch=10,epochs=20,validation_data=validation_generator,validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505/505 [==============================] - 3s 6ms/step\n",
      "loss: 0.0816497783849735 accuracy :  0.06930693069306931\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_data_feature,test_data_label)\n",
    "print('loss:' , score[0], 'accuracy : ',score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### try with VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base = VGG16(weights='imagenet',include_top=False,input_shape=(150, 150, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (500,4,4,512) into shape (500,150,150,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-130-e3239d20852a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m3821\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mfeature_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconv_base\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mtrain_data_feature\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeature_batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mtrain_data_label\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel_batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m<\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (500,4,4,512) into shape (500,150,150,3)"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "batch_size=500\n",
    "for input_batch,label_batch in train_generator:\n",
    "    if ((i*batch_size) < 3821):\n",
    "        feature_batch = conv_base.predict(input_batch)\n",
    "        train_data_feature[i*batch_size:(i+1)*batch_size] = feature_batch\n",
    "        train_data_label[i*batch_size:(i+1)*batch_size] = label_batch\n",
    "    if(len(input_batch)<batch_size):\n",
    "        size=len(input_batch)\n",
    "        feature_batch = conv_base.predict(input_batch)\n",
    "        train_data_feature[i*batch_size:size] = feature_batch\n",
    "        train_data_label[i*batch_size:size] = label_batch\n",
    "    else:\n",
    "        break\n",
    "    i=i+1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "batch_size=50\n",
    "for input_batch,label_batch in validation_generator:\n",
    "    if ((i*batch_size) < 3821):\n",
    "        feature_batch = conv_base.predict(input_batch)\n",
    "        test_data_feature[i*batch_size:(i+1)*batch_size] = feature_batch\n",
    "        test_data_label[i*batch_size:(i+1)*batch_size] = label_batch\n",
    "    if(len(input_batch)<batch_size):\n",
    "        feature_batch = conv_base.predict(input_batch)\n",
    "        size=len(input_batch)\n",
    "        test_data_feature[i*batch_size:size] = feature_batch\n",
    "        test_data_label[i*batch_size:size] = label_batch\n",
    "    else:\n",
    "        break\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 150, 150, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 150, 150, 32)      896       \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 150, 150, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 75, 75, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 75, 75, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 75, 75, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 75, 75, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 37, 37, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 37, 37, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 43808)             0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 512)               22430208  \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 22,461,413\n",
      "Trainable params: 22,461,413\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python3\\lib\\site-packages\\ipykernel_launcher.py:16: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "visible= Input(shape=(150,150,3))\n",
    "conv2d_1 = Conv2D(32,(3,3),activation='relu',padding='same')(visible)\n",
    "conv2d_2 = Conv2D(32,(3,3),activation='relu',padding='same')(conv2d_1)\n",
    "pool1= MaxPool2D(pool_size=(2,2))(conv2d_2)\n",
    "dropout1=Dropout(0.5)(pool1)\n",
    "\n",
    "conv2d_3 = Conv2D(32,(3,3),activation='relu',padding='same')(dropout1)\n",
    "conv2d_4 = Conv2D(32,(3,3),activation='relu',padding='same')(conv2d_3)\n",
    "pool2= MaxPool2D(pool_size=(2,2))(conv2d_4)\n",
    "dropout2=Dropout(0.5)(pool2)\n",
    "\n",
    "flat=Flatten()(dropout2)\n",
    "dense= Dense(512,activation='relu')(flat)\n",
    "dropout3=Dropout(0.5)(dense)\n",
    "output = Dense(5,activation='softmax')(dropout3)\n",
    "model = Model(input=visible,output=output)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3821 samples, validate on 505 samples\n",
      "Epoch 1/12\n",
      "3821/3821 [==============================] - 228s 60ms/step - loss: 0.2374 - acc: 0.2620 - val_loss: 0.1535 - val_acc: 0.0317\n",
      "Epoch 2/12\n",
      "3821/3821 [==============================] - 241s 63ms/step - loss: 0.1949 - acc: 0.0803 - val_loss: 0.1411 - val_acc: 0.0356\n",
      "Epoch 3/12\n",
      "3821/3821 [==============================] - 234s 61ms/step - loss: 0.1783 - acc: 0.1856 - val_loss: 0.1266 - val_acc: 0.0317\n",
      "Epoch 4/12\n",
      "3821/3821 [==============================] - 225s 59ms/step - loss: 0.1748 - acc: 0.2748 - val_loss: 0.1376 - val_acc: 0.9406\n",
      "Epoch 5/12\n",
      "3821/3821 [==============================] - 216s 56ms/step - loss: 0.1579 - acc: 0.6880 - val_loss: 0.1243 - val_acc: 0.9446\n",
      "Epoch 6/12\n",
      "3821/3821 [==============================] - 210s 55ms/step - loss: 0.1548 - acc: 0.7864 - val_loss: 0.1413 - val_acc: 0.0356\n",
      "Epoch 7/12\n",
      "3821/3821 [==============================] - 211s 55ms/step - loss: 0.1448 - acc: 0.7867 - val_loss: 0.0974 - val_acc: 0.9485\n",
      "Epoch 8/12\n",
      "3821/3821 [==============================] - 220s 58ms/step - loss: 0.1272 - acc: 0.6443 - val_loss: 0.1044 - val_acc: 0.0535\n",
      "Epoch 9/12\n",
      "3821/3821 [==============================] - 210s 55ms/step - loss: 0.1135 - acc: 0.3549 - val_loss: 0.1090 - val_acc: 0.0495\n",
      "Epoch 10/12\n",
      "3821/3821 [==============================] - 216s 56ms/step - loss: 0.1010 - acc: 0.1073 - val_loss: 0.1192 - val_acc: 0.0515\n",
      "Epoch 11/12\n",
      "3821/3821 [==============================] - 253s 66ms/step - loss: 0.0796 - acc: 0.1180 - val_loss: 0.0878 - val_acc: 0.0634\n",
      "Epoch 12/12\n",
      "3821/3821 [==============================] - 213s 56ms/step - loss: 0.0656 - acc: 0.1152 - val_loss: 0.1001 - val_acc: 0.0614\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x235bbd88>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['acc'])\n",
    "model.fit(train_data_feature,train_data_label,batch_size=50,epochs=12,validation_data=(test_data_feature,test_data_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505/505 [==============================] - 5s 11ms/step\n",
      "loss: 0.100077751839515 accuracy :  0.061386138613861385\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_data_feature,test_data_label)\n",
    "print('loss:' , score[0], 'accuracy : ',score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
