{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "features=[\"Plasma\",\"BMI\",\"AGE\",\"PEDIGREE\",\"BP\",\"NOP\",\"SERUM_INSULIN\",\"TSKIN_THICKNESS\",\"Target\"]\n",
    "attributesToClean = [\"Plasma\",\"BMI\",\"BP\"]\n",
    "\n",
    "def load_data(path):\n",
    "    diabetes = pd.read_csv(path,header=0)\n",
    "    return diabetes\n",
    "\n",
    "def load_diabetes_data():\n",
    "    PATH = \"datasets/Diabetes/pima-indians-diabetes.csv\"\n",
    "    diabetes_df = load_data(PATH)\n",
    "    feature_names = diabetes_df.columns.array.copy()\n",
    "    return diabetes_df,feature_names\n",
    "    \n",
    "def Separate_X_y_data(data):\n",
    "    np.random.seed(42)\n",
    "    shuffled_indices = np.random.permutation(len(data))\n",
    "    data = data.iloc[shuffled_indices]\n",
    "    y = data[[\"Target\"]]\n",
    "    X = data.drop(columns='Target')\n",
    "    return X,y\n",
    "\n",
    "# This returns X_train, X_test, y_train, y_test\n",
    "def produce_train_test_data(data,test_ratio):\n",
    "    test_set_size = int(len(data)*test_ratio)\n",
    "    return data[test_set_size:], data[:test_set_size]\n",
    "\n",
    "class RemoveInvalidZeroValuesAttributes(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,attributes):\n",
    "        self.attributes = attributes\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    def transform(self,X,y=None):\n",
    "        attrs = self.attributes\n",
    "        for attribute in attrs:\n",
    "            X= X[X[attribute]>0]\n",
    "        return X\n",
    "\n",
    "class FeatureSelection(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,features):\n",
    "        self.features = features\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    def transform(self,X,y=None):\n",
    "        features = self.features\n",
    "        X = X[features]\n",
    "        return X\n",
    "\n",
    "def preprocess_data(X,features,attributes):\n",
    "    data_preprocess_pipeline = Pipeline([(\"feature_selection\",FeatureSelection(features)),(\"clean_zero\",RemoveInvalidZeroValuesAttributes(attributes)),])\n",
    "    #data_preprocess_pipeline = Pipeline([(\"clean_zero\",RemoveInvalidZeroValuesAttributes(attributes)),])\n",
    "    X = data_preprocess_pipeline.fit_transform(X)\n",
    "    return X\n",
    "\n",
    "def scaleAndPreprocessData(data,features,attributes):\n",
    "    data = preprocess_data(data,features,attributes)\n",
    "    X,y = Separate_X_y_data(data)\n",
    "    col = X.columns.array.copy()\n",
    "    scaler = StandardScaler()\n",
    "    X=scaler.fit_transform(X)\n",
    "    X = pd.DataFrame(data=X,columns=col)\n",
    "    return X, y\n",
    "    \n",
    "# trying chapter 7 concepts\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def getPerformances(X_train, X_test, y_train, y_test):\n",
    "    clf_name = []\n",
    "    clf_performance = []\n",
    "    rnd_clf = RandomForestClassifier()\n",
    "    log_clf = LogisticRegression()\n",
    "    svm_clf = SVC()\n",
    "    tree_clf = DecisionTreeClassifier()\n",
    "    KNN_clf = KNeighborsClassifier()\n",
    "    gradient_clf = GradientBoostingClassifier()\n",
    "    voting_clf = VotingClassifier(\n",
    "        estimators = [('lr',log_clf),('rf',rnd_clf),('svc',svm_clf),('tree',tree_clf),('KNN',KNN_clf),('gradient',gradient_clf)],voting = 'hard')\n",
    "    voting_clf.fit(X_train,y_train)\n",
    "    bag_clf = BaggingClassifier(DecisionTreeClassifier(),n_estimators=100,max_samples=1.0,bootstrap=True,n_jobs=-1)\n",
    "    pasting_clf = BaggingClassifier(DecisionTreeClassifier(),n_estimators=500,max_samples=1.0,bootstrap=False,n_jobs=-1,bootstrap_features=True,max_features=1.0)\n",
    "    ada_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=3),n_estimators=15, algorithm=\"SAMME.R\", learning_rate=0.5)\n",
    "    for clf in (log_clf,rnd_clf,svm_clf,voting_clf,tree_clf,KNN_clf,gradient_clf,bag_clf,pasting_clf,ada_clf):\n",
    "        clf.fit(X_train,y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        clf_name.append(clf.__class__.__name__)\n",
    "        score = accuracy_score(y_test,y_pred)\n",
    "        clf_performance.append(score)\n",
    "        print(clf.__class__.__name__,accuracy_score(y_test,y_pred))\n",
    "    return clf_name,clf_performance\n",
    "        \n",
    "def getScoreTrainTest(X_train, X_test, y_train, y_test,clf):\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_tarin_pred = clf.predict(X_train)\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    training_score = accuracy_score(y_train,y_tarin_pred)\n",
    "    testing_score = accuracy_score(y_test,y_test_pred)\n",
    "    return training_score,testing_score\n",
    "\n",
    "def getPerformanceCV(X_train, y_train,scoring):\n",
    "    clf_name = []\n",
    "    clf_performance = []\n",
    "    rnd_clf = RandomForestClassifier()\n",
    "    log_clf = LogisticRegression()\n",
    "    svm_clf = SVC()\n",
    "    tree_clf = DecisionTreeClassifier()\n",
    "    KNN_clf = KNeighborsClassifier()\n",
    "    gradient_clf = GradientBoostingClassifier()\n",
    "    bag_clf = BaggingClassifier(DecisionTreeClassifier(),n_estimators=100,max_samples=1.0,bootstrap=True,n_jobs=-1)\n",
    "    pasting_clf = BaggingClassifier(DecisionTreeClassifier(),n_estimators=500,max_samples=1.0,bootstrap=False,n_jobs=-1,bootstrap_features=True,max_features=1.0)\n",
    "    ada_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=3),n_estimators=15, algorithm=\"SAMME.R\", learning_rate=0.5)\n",
    "    score_df = pd.DataFrame(columns=[\"classifier\",\"mean\",\"min\",\"max\",\"deviation\"])\n",
    "    count = 0\n",
    "    for clf in (log_clf,rnd_clf,svm_clf,tree_clf,KNN_clf,gradient_clf,bag_clf,pasting_clf,ada_clf):\n",
    "        score = cross_val_score(clf,X_train,y_train,cv=4,scoring=scoring)\n",
    "        mean = score.mean()\n",
    "        deviation = score.std() * 2\n",
    "        maximum = mean+deviation\n",
    "        minimum = mean-deviation\n",
    "        score_df.loc[count] = [clf.__class__.__name__,mean,minimum,maximum,deviation]\n",
    "        count = count+1\n",
    "    return score_df\n",
    "    \n",
    "# TODO : Need to look into how to calculate AUC for voting classifier\n",
    "def getAUCScore(X_train, y_train):\n",
    "    clf_name = []\n",
    "    clf_performance = []\n",
    "    rnd_clf = RandomForestClassifier()\n",
    "    log_clf = LogisticRegression()\n",
    "    svm_clf = SVC(random_state=42)\n",
    "    tree_clf = DecisionTreeClassifier()\n",
    "    KNN_clf = KNeighborsClassifier()\n",
    "    gradient_clf = GradientBoostingClassifier()\n",
    "    bag_clf = BaggingClassifier(DecisionTreeClassifier(),n_estimators=100,max_samples=0.40,bootstrap=True,n_jobs=-1)\n",
    "    pasting_clf = BaggingClassifier(DecisionTreeClassifier(),n_estimators=500,max_samples=0.40,bootstrap=False,n_jobs=-1,bootstrap_features=True,max_features=1.0)\n",
    "    ada_clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=3),n_estimators=15, algorithm=\"SAMME.R\", learning_rate=0.5)\n",
    "    score_df = pd.DataFrame(columns=[\"classifier\",\"score\"])\n",
    "    count = 0\n",
    "    for clf in (log_clf,rnd_clf,svm_clf,tree_clf,KNN_clf,gradient_clf,bag_clf,pasting_clf,ada_clf):\n",
    "        name = clf.__class__.__name__\n",
    "        if name in ['SVC','Logistic Regression']:\n",
    "            y_scores = cross_val_predict(clf,X_train,y_train,cv=3, method=\"decision_function\")\n",
    "            score = roc_auc_score(y_train, y_scores)\n",
    "        elif name in ['VotingClassifier']:\n",
    "            score = cross_val_score(clf,X_train,y_train,cv=4,scoring=\"accuracy\").mean()\n",
    "        else:\n",
    "            print(name)\n",
    "            y_scores = cross_val_predict(clf,X_train,y_train,cv=3, method = \"predict_proba\")\n",
    "            y_scores = y_scores[:,1]\n",
    "            score = roc_auc_score(y_train, y_scores)\n",
    "        clf_name.append(name)\n",
    "        clf_performance.append(score)\n",
    "        print(name,score)\n",
    "        score_df.loc[count] = [name,score]\n",
    "        count =count+1\n",
    "    return score_df\n",
    "\n",
    "def getAUC_ROC_score(X_train, y_train,clf,method):\n",
    "    if method in (['decision_function','accuracy']):\n",
    "        y_scores = cross_val_predict(clf,X_train,y_train,cv=3, method=\"decision_function\")\n",
    "        score = roc_auc_score(y_train, y_scores)\n",
    "    if method in ('predict_proba'):\n",
    "        y_scores = cross_val_predict(clf,X_train,y_train,cv=3, method = \"predict_proba\")\n",
    "        y_scores = y_scores[:,1]\n",
    "        score = roc_auc_score(y_train, y_scores)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_df,feature_names = load_diabetes_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = produce_train_test_data(diabetes_df,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep aside test data and train model on training data.\n",
    "train_data_cleaned = preprocess_data(train,features,attributesToClean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scaling on train data\n",
    "X_train,y_train = Separate_X_y_data(train_data_cleaned)\n",
    "scale = StandardScaler()\n",
    "scale.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([121.60091743,  32.47996942,  33.06727829,   0.46812538,\n",
       "         72.33486239,   3.77828746,  84.08562691,  21.5030581 ]),\n",
       " array([9.26215351e+02, 4.73477486e+01, 1.38845627e+02, 1.03763342e-01,\n",
       "        1.49626399e+02, 1.10991616e+01, 1.29885768e+04, 2.45256107e+02]),\n",
       " array([ 30.43378634,   6.88097004,  11.78327741,   0.32212318,\n",
       "         12.23218702,   3.33154042, 113.96743731,  15.66065474]))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale.mean_,scale.var_,scale.scale_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python27\\lib\\site-packages\\ipykernel_launcher.py:2: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# will use same scaler for tranforming test data.\n",
    "X_train_scaled = scale.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now try models using cross validation with and without scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic has mean 76.45 with +/- .029 deviation 2sigma, for 95% confidence interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top rankers;1. Bagging,Random forest, Gradient,Logistic, Adaboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('classifier', 'LogisticRegression', 0.7782859078590785, 0.05198181493656188, 'Range:', 0.8302677227956403, ':', 0.7263040929225166)\n",
      "('classifier', 'RandomForestClassifier', 0.7721130683529058, 0.022527123854489926, 'Range:', 0.7946401922073958, ':', 0.7495859444984159)\n",
      "('classifier', 'SVC', 0.7721130683529058, 0.04864651890648993, 'Range:', 0.8207595872593958, ':', 0.7234665494464159)\n",
      "('classifier', 'VotingClassifier', 0.7676339957844023, 0.03635467891499828, 'Range:', 0.8039886746994006, ':', 0.731279316869404)\n",
      "('classifier', 'DecisionTreeClassifier', 0.7110245408009636, 0.036367302757740305, 'Range:', 0.7473918435587039, ':', 0.6746572380432232)\n",
      "('classifier', 'KNeighborsClassifier', 0.7507716049382716, 0.04488739224034129, 'Range:', 0.7956589971786129, ':', 0.7058842126979302)\n",
      "('classifier', 'GradientBoostingClassifier', 0.7737127371273713, 0.04365583656798652, 'Range:', 0.8173685736953579, ':', 0.7300569005593848)\n",
      "('classifier', 'BaggingClassifier', 0.7874322493224932, 0.017256484589363207, 'Range:', 0.8046887339118565, ':', 0.77017576473313)\n",
      "('classifier', 'BaggingClassifier', 0.7446928635953027, 0.02745644444633687, 'Range:', 0.7721493080416396, ':', 0.7172364191489659)\n",
      "('classifier', 'AdaBoostClassifier', 0.7460666967780789, 0.04295870443410548, 'Range:', 0.7890254012121843, ':', 0.7031079923439735)\n"
     ]
    }
   ],
   "source": [
    "#withh scaling\n",
    "score_df = getPerformanceCV(X_train_scaled,y_train,\"accuracy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>mean</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>deviation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>0.787432</td>\n",
       "      <td>0.770176</td>\n",
       "      <td>0.804689</td>\n",
       "      <td>0.017256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.778286</td>\n",
       "      <td>0.726304</td>\n",
       "      <td>0.830268</td>\n",
       "      <td>0.051982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.773713</td>\n",
       "      <td>0.730057</td>\n",
       "      <td>0.817369</td>\n",
       "      <td>0.043656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.772113</td>\n",
       "      <td>0.749586</td>\n",
       "      <td>0.794640</td>\n",
       "      <td>0.022527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.772113</td>\n",
       "      <td>0.723467</td>\n",
       "      <td>0.820760</td>\n",
       "      <td>0.048647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VotingClassifier</td>\n",
       "      <td>0.767634</td>\n",
       "      <td>0.731279</td>\n",
       "      <td>0.803989</td>\n",
       "      <td>0.036355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.750772</td>\n",
       "      <td>0.705884</td>\n",
       "      <td>0.795659</td>\n",
       "      <td>0.044887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.746067</td>\n",
       "      <td>0.703108</td>\n",
       "      <td>0.789025</td>\n",
       "      <td>0.042959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>0.744693</td>\n",
       "      <td>0.717236</td>\n",
       "      <td>0.772149</td>\n",
       "      <td>0.027456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.711025</td>\n",
       "      <td>0.674657</td>\n",
       "      <td>0.747392</td>\n",
       "      <td>0.036367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   classifier      mean       min       max  deviation\n",
       "7           BaggingClassifier  0.787432  0.770176  0.804689   0.017256\n",
       "0          LogisticRegression  0.778286  0.726304  0.830268   0.051982\n",
       "6  GradientBoostingClassifier  0.773713  0.730057  0.817369   0.043656\n",
       "1      RandomForestClassifier  0.772113  0.749586  0.794640   0.022527\n",
       "2                         SVC  0.772113  0.723467  0.820760   0.048647\n",
       "3            VotingClassifier  0.767634  0.731279  0.803989   0.036355\n",
       "5        KNeighborsClassifier  0.750772  0.705884  0.795659   0.044887\n",
       "9          AdaBoostClassifier  0.746067  0.703108  0.789025   0.042959\n",
       "8           BaggingClassifier  0.744693  0.717236  0.772149   0.027456\n",
       "4      DecisionTreeClassifier  0.711025  0.674657  0.747392   0.036367"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df.sort_values(ascending=False,by=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "('LogisticRegression', 0.8438356164383563)\n",
      "RandomForestClassifier\n",
      "('RandomForestClassifier', 0.7900120715897759)\n",
      "('SVC', 0.8268724085445862)\n",
      "('VotingClassifier', 0.7782859078590786)\n",
      "DecisionTreeClassifier\n",
      "('DecisionTreeClassifier', 0.6510470792001259)\n",
      "KNeighborsClassifier\n",
      "('KNeighborsClassifier', 0.7737101768750329)\n",
      "GradientBoostingClassifier\n",
      "('GradientBoostingClassifier', 0.8152416942213825)\n",
      "BaggingClassifier\n",
      "('BaggingClassifier', 0.8257124862226422)\n",
      "BaggingClassifier\n",
      "('BaggingClassifier', 0.8284837033538026)\n",
      "AdaBoostClassifier\n",
      "('AdaBoostClassifier', 0.7442030126489266)\n"
     ]
    }
   ],
   "source": [
    "scoredf=getAUCScore(X_train=X_train_scaled,y_train=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.843836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>0.828484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.826872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>0.825712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.815242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.790012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VotingClassifier</td>\n",
       "      <td>0.778286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.773710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.744203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.651047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   classifier     score\n",
       "0          LogisticRegression  0.843836\n",
       "8           BaggingClassifier  0.828484\n",
       "2                         SVC  0.826872\n",
       "7           BaggingClassifier  0.825712\n",
       "6  GradientBoostingClassifier  0.815242\n",
       "1      RandomForestClassifier  0.790012\n",
       "3            VotingClassifier  0.778286\n",
       "5        KNeighborsClassifier  0.773710\n",
       "9          AdaBoostClassifier  0.744203\n",
       "4      DecisionTreeClassifier  0.651047"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoredf.sort_values(by=\"score\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now top rankers are LogisticRegression,RandomForestClassifier,BaggingClassifier,GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall performance rankers, LogisticRegression,SVC,BaggingClassifier,GradientBoostingClassifier,RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### analyze train test errors in cross validation.LogisticRegression,SVC,BaggingClassifier,GradientBoostingClassifier,RandomForestClassifier have higher accuracy as well as higher AUC score for overall performance. so picking these to fine tune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.764525993883792, 0.8417431192660549)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf = SVC(random_state=42)\n",
    "scores = cross_validate(estimator=svm_clf,X=X_train_scaled,y=y_train,scoring=\"accuracy\",cv=3,n_jobs=-1,return_train_score=True)\n",
    "test_score=scores[\"test_score\"].mean() \n",
    "train_score=scores[\"train_score\"].mean() \n",
    "test_score,train_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.0079999 , 0.00800014, 0.00299978]),\n",
       " 'score_time': array([0.00200009, 0.00199986, 0.        ]),\n",
       " 'test_score': array([0.81192661, 0.74770642, 0.73394495]),\n",
       " 'train_score': array([0.8440367 , 0.85091743, 0.83027523])}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def validateModels(X_train, y_train,scoring):\n",
    "    rnd_clf = RandomForestClassifier()\n",
    "    log_clf = LogisticRegression()\n",
    "    svm_clf = SVC(random_state=42)\n",
    "    gradient_clf = GradientBoostingClassifier()\n",
    "    bag_clf = BaggingClassifier(DecisionTreeClassifier(),n_estimators=100,max_samples=0.40,bootstrap=True,n_jobs=-1)\n",
    "    score_df = pd.DataFrame(columns=[\"classifier\",\"train_score\",\"test_score\"])\n",
    "    count = 0\n",
    "    for clf in (log_clf,rnd_clf,svm_clf,gradient_clf,bag_clf):\n",
    "        name = clf.__class__.__name__\n",
    "        scores = cross_validate(estimator=clf,X=X_train,y=y_train,scoring=scoring,cv=3,n_jobs=-1,return_train_score=True)\n",
    "        test_score=scores[\"test_score\"].mean() \n",
    "        train_score=scores[\"train_score\"].mean()\n",
    "        score_df.loc[count] = [name,train_score,test_score]\n",
    "        count =count+1\n",
    "    return score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df=validateModels(X_train_scaled,y_train,\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.785933</td>\n",
       "      <td>0.788991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.982416</td>\n",
       "      <td>0.740061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.841743</td>\n",
       "      <td>0.764526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.961774</td>\n",
       "      <td>0.756881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>0.927370</td>\n",
       "      <td>0.772171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   classifier  train_score  test_score\n",
       "0          LogisticRegression     0.785933    0.788991\n",
       "1      RandomForestClassifier     0.982416    0.740061\n",
       "2                         SVC     0.841743    0.764526\n",
       "3  GradientBoostingClassifier     0.961774    0.756881\n",
       "4           BaggingClassifier     0.927370    0.772171"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Except logistic all are overfitting. Random forest is most overfitting. SVC also less overfitting than otherson accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df=validateModels(X_train_scaled,y_train,\"roc_auc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.854889</td>\n",
       "      <td>0.844151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.999543</td>\n",
       "      <td>0.789860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.913801</td>\n",
       "      <td>0.830389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.994607</td>\n",
       "      <td>0.817761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>0.985317</td>\n",
       "      <td>0.816863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   classifier  train_score  test_score\n",
       "0          LogisticRegression     0.854889    0.844151\n",
       "1      RandomForestClassifier     0.999543    0.789860\n",
       "2                         SVC     0.913801    0.830389\n",
       "3  GradientBoostingClassifier     0.994607    0.817761\n",
       "4           BaggingClassifier     0.985317    0.816863"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For AUC score, Logistic is least overfitting, random forest and Gradient are so overfitting that training score is almost 100% but not doing great on test score. Again SVC is moderatively overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0, 'warm_start': True}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets fine tune the above ones\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid_val = ({'C' : [1.0,0.9,0.8],'warm_start' : [True,False]})\n",
    "logistic_clf = LogisticRegression(random_state=42)\n",
    "grid_logistic = GridSearchCV(cv=4,estimator=logistic_clf,param_grid=param_grid_val)\n",
    "grid_logistic.fit(X_train_scaled,y_train)\n",
    "grid_logistic.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0, 'warm_start': True}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_logistic.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_clf = LogisticRegression(warm_start=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_AUC = getAUC_ROC_score(X_train_scaled,y_train,logistic_clf,'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8438356164383563"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8441505274759881, 0.8548889938592348)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_validate(estimator=logistic_clf,X=X_train_scaled,y=y_train,scoring=\"roc_auc\",cv=3,n_jobs=-1,return_train_score=True)\n",
    "test_score=scores[\"test_score\"].mean() \n",
    "train_score=scores[\"train_score\"].mean() \n",
    "test_score,train_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8441505274759881, 0.8548889938592348)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_clf = LogisticRegression()\n",
    "scores = cross_validate(estimator=logistic_clf,X=X_train_scaled,y=y_train,scoring=\"roc_auc\",cv=3,n_jobs=-1,return_train_score=True)\n",
    "test_score=scores[\"test_score\"].mean() \n",
    "train_score=scores[\"train_score\"].mean() \n",
    "test_score,train_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seems like default logistic is best model. There was nothing much to fine tune logistic, now do this for SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There was nothing much to fine tune logistic, now do this for SVC\n",
    "param_grid_val = ({'gamma':[0.1,0.2,0.3,0.4],'kernel':['poly', 'rbf', 'sigmoid']},\n",
    "                  {'kernel':['linear']})\n",
    "clf_svc = SVC()\n",
    "grid_SVC = GridSearchCV(cv=4,estimator=clf_svc,param_grid=param_grid_val,scoring=\"roc_auc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=4, error_score='raise-deprecating',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid=({'kernel': ['poly', 'rbf', 'sigmoid'], 'gamma': [0.1, 0.2, 0.3, 0.4]}, {'kernel': ['linear']}),\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_SVC.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kernel': 'linear'}"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_SVC.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8442074420948252"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_SVC.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8479294599275704, 0.8528184537868052)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_svc = SVC(kernel='linear',random_state=42)\n",
    "scores = cross_validate(estimator=clf_svc,X=X_train_scaled,y=y_train,scoring=\"roc_auc\",cv=3,n_jobs=-1,return_train_score=True)\n",
    "test_score=scores[\"test_score\"].mean() \n",
    "train_score=scores[\"train_score\"].mean() \n",
    "test_score,train_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8303889151314753, 0.9138009762242166)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_svc = SVC(random_state=42)\n",
    "scores = cross_validate(estimator=clf_svc,X=X_train_scaled,y=y_train,scoring=\"roc_auc\",cv=3,n_jobs=-1,return_train_score=True)\n",
    "test_score=scores[\"test_score\"].mean() \n",
    "train_score=scores[\"train_score\"].mean() \n",
    "test_score,train_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doing grid search for roc_auc scoring, SVM gives kernel=linear the best param. Using it increases test score from 83 to 84 and decreases training score from 91 to 85. Hence for linear it is more generalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'n_estimators': [5, 10, 20, 30, 40], 'max_leaf_nodes': [12, 14, 16, 18]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rnd_clf=RandomForestClassifier()\n",
    "param_grid_val={'n_estimators':[5,10,20,30,40],'max_leaf_nodes':[12,14,16,18]}\n",
    "gris_rnd = GridSearchCV(cv=3,estimator=rnd_clf,param_grid=param_grid_val,scoring=\"roc_auc\")\n",
    "gris_rnd.fit(X_train_scaled,y_train)\n",
    "\n",
    "#rnd_clf = RandomForestClassifier(n_estimators=500,max_leaf_nodes=16,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_leaf_nodes': 14, 'n_estimators': 30}"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gris_rnd.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8320894347346875, 0.9378523067233507)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using best parameters for random forest.\n",
    "rnd_clf = RandomForestClassifier(n_estimators=30,max_leaf_nodes=14,n_jobs=-1)\n",
    "scores = cross_validate(estimator=rnd_clf,X=X_train_scaled,y=y_train,scoring=\"roc_auc\",cv=3,n_jobs=-1,return_train_score=True)\n",
    "test_score=scores[\"test_score\"].mean() \n",
    "train_score=scores[\"train_score\"].mean() \n",
    "test_score,train_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8030231459612659, 0.9989293024720517)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_clf = RandomForestClassifier()\n",
    "scores = cross_validate(estimator=rnd_clf,X=X_train_scaled,y=y_train,scoring=\"roc_auc\",cv=3,n_jobs=-1,return_train_score=True)\n",
    "test_score=scores[\"test_score\"].mean() \n",
    "train_score=scores[\"train_score\"].mean() \n",
    "test_score,train_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After using best parameter it is more generalized as test score goes up from 80 to 83 and training data is not overfitted as it goes down from 99 percent to 93 percent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fine tune gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x18625ba8>]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check best number of estimator\n",
    "estomator_number=[]\n",
    "scoreBag = []\n",
    "for n_estimator in [50,60,70,80,90,100]:\n",
    "    gradient_clf = GradientBoostingClassifier(max_depth=100,n_estimators=n_estimator,learning_rate=1.0,random_state=42)\n",
    "    gradient_clf.fit(X_train_scaled,y_train)\n",
    "    y_pred = gradient_clf.predict(X_test)\n",
    "    score = roc_auc_score(y_test,y_pred)\n",
    "    estomator_number.append(n_estimator)\n",
    "    scoreBag.append(score)\n",
    "\n",
    "plt.plot(estomator_number,scoreBag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### why this is a straight line?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_sampl...      subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'n_estimators': [50, 60, 70, 80, 90, 100], 'max_depth': [1, 2, 3, 4, 5, 6, 7, 10, 20, 30, 40, 50, 60, 70]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_clf = GradientBoostingClassifier(random_state=42)\n",
    "param_grid_val={'n_estimators':[50,60,70,80,90,100],'max_depth':[1,2,3,4,5,6,7,10,20,30,40,50,60,70]}\n",
    "gris_rnd = GridSearchCV(cv=3,estimator=gradient_clf,param_grid=param_grid_val,scoring=\"roc_auc\")\n",
    "gris_rnd.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 1, 'n_estimators': 100}"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gris_rnd.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8373169579593766, 0.8970634545740829)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_clf = GradientBoostingClassifier(random_state=42,max_depth=1,n_estimators=100)\n",
    "scores = cross_validate(estimator=gradient_clf,X=X_train_scaled,y=y_train,scoring=\"roc_auc\",cv=3,n_jobs=-1,return_train_score=True)\n",
    "test_score=scores[\"test_score\"].mean() \n",
    "train_score=scores[\"train_score\"].mean() \n",
    "test_score,train_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8184222957014643, 0.9946071484805543)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_clf = GradientBoostingClassifier(random_state=42)\n",
    "scores = cross_validate(estimator=gradient_clf,X=X_train_scaled,y=y_train,scoring=\"roc_auc\",cv=3,n_jobs=-1,return_train_score=True)\n",
    "test_score=scores[\"test_score\"].mean() \n",
    "train_score=scores[\"train_score\"].mean() \n",
    "test_score,train_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best parameter of {'max_depth': 1, 'n_estimators': 100} increased score percentage from 81 to 83 and decreased training score from 99 to 89. Hence, with best parameters it is more generalized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tune last model bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            ..._estimators=10, n_jobs=-1, oob_score=False,\n",
       "         random_state=None, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'n_estimators': [400, 410, 420], 'max_samples': [40, 50, 60, 70]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(),bootstrap=False,n_jobs=-1\n",
    ")\n",
    "param_grid_val={'n_estimators':[400,410,420],'max_samples':[40,50,60,70]}\n",
    "gris_rnd = GridSearchCV(cv=3,estimator=bag_clf,param_grid=param_grid_val,scoring=\"roc_auc\")\n",
    "gris_rnd.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_samples': 60, 'n_estimators': 420}"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gris_rnd.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8305306250984096, 0.9221658006613133)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using best paramters\n",
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(),bootstrap=False,n_jobs=-1,n_estimators=420,max_samples=60\n",
    ")\n",
    "scores = cross_validate(estimator=bag_clf,X=X_train_scaled,y=y_train,scoring=\"roc_auc\",cv=3,n_jobs=-1,return_train_score=True)\n",
    "test_score=scores[\"test_score\"].mean() \n",
    "train_score=scores[\"train_score\"].mean() \n",
    "test_score,train_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6668083766336009, 1.0)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(),bootstrap=False,n_jobs=-1\n",
    ")\n",
    "scores = cross_validate(estimator=bag_clf,X=X_train_scaled,y=y_train,scoring=\"roc_auc\",cv=3,n_jobs=-1,return_train_score=True)\n",
    "test_score=scores[\"test_score\"].mean() \n",
    "train_score=scores[\"train_score\"].mean() \n",
    "test_score,train_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best parameter improved expremely fit model of training score 1 with test score 67% to 83 test score and 92 training score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of fine tuned models\n",
    "#logistic- default\n",
    "#SVC - default\n",
    "#Bagging - \n",
    "# Ada- ada_clf = DecisionTreeClassifier(max_depth=3),n_estimators=14, algorithm=\"SAMME.R\", learning_rate=0.5\n",
    "# RandomForest - rnd_clf = RandomForestClassifier(n_estimators=30,max_leaf_nodes=16,n_jobs=-1)\n",
    "# Gradient - gradient_clf = GradientBoostingClassifier(max_depth=60,n_estimators=80,learning_rate=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test all models with their best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running all once again\n",
    "\n",
    "def getPerformanceCVSelected(X_train, y_train):\n",
    "    clf_name = []\n",
    "    clf_performance = []\n",
    "    rnd_clf = RandomForestClassifier(n_estimators=30,max_leaf_nodes=14,n_jobs=-1)\n",
    "    log_clf = LogisticRegression()\n",
    "    svm_clf = SVC(kernel='linear',random_state=42)\n",
    "    gradient_clf = GradientBoostingClassifier(random_state=42,max_depth=1,n_estimators=100)\n",
    "    bag_clf = BaggingClassifier(DecisionTreeClassifier(),n_estimators=420,max_samples=60,bootstrap=True,n_jobs=-1)\n",
    "    score_df = pd.DataFrame(columns=[\"classifier\",\"train_score\",\"test_score\"])\n",
    "    count=0\n",
    "    for clf in (log_clf,rnd_clf,svm_clf,gradient_clf,bag_clf):\n",
    "        scores = cross_validate(estimator=clf,X=X_train,y=y_train,scoring=\"roc_auc\",cv=3,n_jobs=-1,return_train_score=True)\n",
    "        test_score=scores[\"test_score\"].mean() \n",
    "        train_score=scores[\"train_score\"].mean() \n",
    "        score_df.loc[count] = [clf.__class__.__name__,train_score,test_score]\n",
    "        count= count+1\n",
    "    return score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df = getPerformanceCVSelected(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.852818</td>\n",
       "      <td>0.847929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.854889</td>\n",
       "      <td>0.844151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.897063</td>\n",
       "      <td>0.837317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.937545</td>\n",
       "      <td>0.832845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>0.919647</td>\n",
       "      <td>0.828263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   classifier  train_score  test_score\n",
       "2                         SVC     0.852818    0.847929\n",
       "0          LogisticRegression     0.854889    0.844151\n",
       "3  GradientBoostingClassifier     0.897063    0.837317\n",
       "1      RandomForestClassifier     0.937545    0.832845\n",
       "4           BaggingClassifier     0.919647    0.828263"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df.sort_values(by=\"test_score\",ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As per above table, SVC and Logistic are least overfitting. Lets check deviation of test score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPerformanceRangeCVSelected(X_train, y_train):\n",
    "    clf_name = []\n",
    "    clf_performance = []\n",
    "    rnd_clf = RandomForestClassifier(n_estimators=30,max_leaf_nodes=14,n_jobs=-1)\n",
    "    log_clf = LogisticRegression()\n",
    "    svm_clf = SVC(kernel='linear',random_state=42)\n",
    "    gradient_clf = GradientBoostingClassifier(random_state=42,max_depth=1,n_estimators=100)\n",
    "    bag_clf = BaggingClassifier(DecisionTreeClassifier(),n_estimators=420,max_samples=60,bootstrap=True,n_jobs=-1)\n",
    "    score_df = pd.DataFrame(columns=[\"classifier\",\"train_score\",\"test_score\",\"overfitting\",\"test_min\",\"test_max\",\"deviation\"])\n",
    "    count=0\n",
    "    for clf in (log_clf,rnd_clf,svm_clf,gradient_clf,bag_clf):\n",
    "        scores = cross_validate(estimator=clf,X=X_train,y=y_train,scoring=\"roc_auc\",cv=3,n_jobs=-1,return_train_score=True)\n",
    "        test_score=scores[\"test_score\"].mean() \n",
    "        train_score=scores[\"train_score\"].mean() \n",
    "        deviation = scores[\"test_score\"].std() * 2\n",
    "        maximum = test_score+deviation\n",
    "        minimum = test_score-deviation\n",
    "        overfitting=train_score-test_score\n",
    "        score_df.loc[count] = [clf.__class__.__name__,train_score,test_score,overfitting,minimum,maximum,deviation]\n",
    "        count= count+1\n",
    "    return score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df = getPerformanceRangeCVSelected(X_train=X_train_scaled,y_train=y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>overfitting</th>\n",
       "      <th>test_min</th>\n",
       "      <th>test_max</th>\n",
       "      <th>deviation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.852818</td>\n",
       "      <td>0.847929</td>\n",
       "      <td>0.004889</td>\n",
       "      <td>0.807052</td>\n",
       "      <td>0.888807</td>\n",
       "      <td>0.040878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.854889</td>\n",
       "      <td>0.844151</td>\n",
       "      <td>0.010738</td>\n",
       "      <td>0.814286</td>\n",
       "      <td>0.874015</td>\n",
       "      <td>0.029865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.897063</td>\n",
       "      <td>0.837317</td>\n",
       "      <td>0.059746</td>\n",
       "      <td>0.786058</td>\n",
       "      <td>0.888576</td>\n",
       "      <td>0.051259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.938183</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.110597</td>\n",
       "      <td>0.801739</td>\n",
       "      <td>0.853433</td>\n",
       "      <td>0.025847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>0.917493</td>\n",
       "      <td>0.823067</td>\n",
       "      <td>0.094426</td>\n",
       "      <td>0.782861</td>\n",
       "      <td>0.863274</td>\n",
       "      <td>0.040207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   classifier  train_score  test_score  overfitting  test_min  \\\n",
       "2                         SVC     0.852818    0.847929     0.004889  0.807052   \n",
       "0          LogisticRegression     0.854889    0.844151     0.010738  0.814286   \n",
       "3  GradientBoostingClassifier     0.897063    0.837317     0.059746  0.786058   \n",
       "1      RandomForestClassifier     0.938183    0.827586     0.110597  0.801739   \n",
       "4           BaggingClassifier     0.917493    0.823067     0.094426  0.782861   \n",
       "\n",
       "   test_max  deviation  \n",
       "2  0.888807   0.040878  \n",
       "0  0.874015   0.029865  \n",
       "3  0.888576   0.051259  \n",
       "1  0.853433   0.025847  \n",
       "4  0.863274   0.040207  "
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df.sort_values(by=\"test_score\",ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC is top performer as it has highest test score, least overfitting model but has second highest deviation. \n",
    "### Logistic has second lowest overfitting, second highest test score and reasonable low deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python27\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# lets test them finally on our actual test data , i would pick logistic\n",
    "test_data_cleaned = preprocess_data(test,features,attributesToClean)\n",
    "X_test,y_test = Separate_X_y_data(test_data_cleaned)\n",
    "X_test = scale.transform(X_test) # transform with same scaler which was used in training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPerformancesSelectedTesting(X_train, X_test, y_train, y_test):\n",
    "    clf_name = []\n",
    "    clf_performance = []\n",
    "    rnd_clf = RandomForestClassifier(n_estimators=30,max_leaf_nodes=14,n_jobs=-1)\n",
    "    log_clf = LogisticRegression()\n",
    "    svm_clf = SVC(kernel='linear',random_state=42)\n",
    "    gradient_clf = GradientBoostingClassifier(random_state=42,max_depth=1,n_estimators=100)\n",
    "    bag_clf = BaggingClassifier(DecisionTreeClassifier(),n_estimators=420,max_samples=60,bootstrap=True,n_jobs=-1)\n",
    "    score_df = pd.DataFrame(columns=[\"classifier\",\"score\"])\n",
    "    count = 0\n",
    "    for clf in (log_clf,rnd_clf,svm_clf,gradient_clf,bag_clf):\n",
    "        clf.fit(X_train,y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        auc_score_val=roc_auc_score(y_test,y_pred)\n",
    "        score_df.loc[count] = [clf.__class__.__name__,auc_score_val]\n",
    "        count= count+1\n",
    "    return score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python27\\lib\\site-packages\\ipykernel_launcher.py:12: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "score_df = getPerformancesSelectedTesting(X_train=X_train_scaled,y_train=y_train,X_test=X_test,y_test=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>0.712500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.708333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   classifier     score\n",
       "4           BaggingClassifier  0.712500\n",
       "1      RandomForestClassifier  0.708333\n",
       "2                         SVC  0.700000\n",
       "0          LogisticRegression  0.687500\n",
       "3  GradientBoostingClassifier  0.683333"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df.sort_values(by=\"score\",ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging is performation best. second best are SVC and random forest. I would pick SVC model as moderate performance on training and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ### On test data, without removing data with 0 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python27\\lib\\site-packages\\ipykernel_launcher.py:3: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# without removing zero fromtest set\n",
    "X_test,y_test = Separate_X_y_data(test)\n",
    "X_test = scale.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python27\\lib\\site-packages\\ipykernel_launcher.py:12: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>0.536932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.522727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.522727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.492898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.478693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   classifier     score\n",
       "4           BaggingClassifier  0.536932\n",
       "0          LogisticRegression  0.522727\n",
       "2                         SVC  0.522727\n",
       "1      RandomForestClassifier  0.492898\n",
       "3  GradientBoostingClassifier  0.478693"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df = getPerformancesSelectedTesting(X_train=X_train_scaled,y_train=y_train,X_test=X_test,y_test=y_test)\n",
    "score_df.sort_values(by=\"score\",ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it is a tie in Logistic,SVC,Bagging and winner is Random forest"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
